{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import os\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pre_processing_data():\n",
    "    def __init__(self, train_data_path, valid_data_path, test_data_path):\n",
    "        self.train_data_path = train_data_path\n",
    "        self.valid_data_path = valid_data_path\n",
    "        self.test_data_path = test_data_path\n",
    "                 \n",
    "    def load_data(self):\n",
    "        self.train_data_org = pd.read_csv(self.train_data_path)\n",
    "        self.valid_data_org = pd.read_csv(self.valid_data_path)\n",
    "        self.test_data_org = pd.read_csv(self.test_data_path)         \n",
    "        \n",
    "    def drop_id_price(self):\n",
    "        train_data_temp = self.train_data_org\n",
    "        train_data_temp.drop(['id','price'],axis=1,inplace=True)\n",
    "        valid_data_temp = self.valid_data_org\n",
    "        valid_data_temp.drop(['id','price'],axis=1,inplace=True)\n",
    "        test_data_temp = self.test_data_org\n",
    "        test_data_temp.drop('id',axis=1,inplace=True)\n",
    "        return train_data_temp.to_numpy(),valid_data_temp.to_numpy(),test_data_temp.to_numpy()\n",
    "    \n",
    "    def mean_std(self):\n",
    "        mean = self.train_data.mean(axis=0)\n",
    "        self.train_data -= mean\n",
    "        std = self.train_data.std(axis=0)\n",
    "        self.train_data /= std\n",
    "        \n",
    "        self.valid_data-=mean\n",
    "        self.valid_data/=std\n",
    "        \n",
    "        self.test_data-=mean\n",
    "        self.test_data/=std\n",
    "        \n",
    "    def get_price_target(self):\n",
    "        train_price_temp = self.train_data_org.price.to_numpy()\n",
    "        valid_price_temp = self.valid_data_org.price.to_numpy()\n",
    "        return train_price_temp,valid_price_temp\n",
    "        \n",
    "    def do_pre_proccessing_data(self): \n",
    "        self.load_data()\n",
    "        self.train_targets, self.valid_targets = self.get_price_target()\n",
    "        self.train_data, self.valid_data, self.test_data = self.drop_id_price()\n",
    "        self.mean_std()\n",
    "        \n",
    "    def show_shape(self): \n",
    "        l_train = self.train_data.shape\n",
    "        l_valid = self.valid_data.shape\n",
    "        l_test = self.test_data.shape\n",
    "        print(f\"l_train:{l_train}, l_valid:{l_valid}, l_test:{l_test}\")\n",
    "\n",
    "    def get_data_shape1(self, input_data): \n",
    "        return input_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pre_processing_data(\"train-v3.csv\", \"valid-v3.csv\", \"test-v3.csv\")\n",
    "all_data.do_pre_proccessing_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "#import tensorflow as tf\n",
    "#tf.config.experimental.list_physical_devices('GPU')\n",
    "# 設定 Keras 使用的 Session\n",
    "\n",
    "def build_model(input_shape1):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(128, activation='relu',input_shape=(input_shape1,)))\n",
    "    model.add(layers.Dense(128, activation='relu',input_shape=(input_shape1,)))\n",
    "    model.add(layers.Dense(128, activation='relu',input_shape=(input_shape1,)))\n",
    "    model.add(layers.Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "k = 4\n",
    "num_val_samples = len(all_data.train_data) // k\n",
    "num_epochs = 5\n",
    "all_mae_histories = []\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    val_data = all_data.train_data[i * num_val_samples: (i+1) * num_val_samples]\n",
    "    val_targets = all_data.train_targets[i * num_val_samples: (i+1) * num_val_samples]\n",
    "    print(val_data)\n",
    "    print(val_data.shape)\n",
    "    \n",
    "    trda1 = all_data.train_data[:i * num_val_samples]\n",
    "    trda2 = all_data.train_data[(i + 1) * num_val_samples:]    \n",
    "    partial_train_data = np.concatenate([trda1,trda2],axis=0)\n",
    "    print(partial_train_data) \n",
    "\n",
    "    trta1 = all_data.train_targets[:i * num_val_samples]\n",
    "    trta2 = all_data.train_targets[(i + 1) * num_val_samples:]\n",
    "    partial_train_targets = np.concatenate([trta1,trta2],axis=0)\n",
    "    print(partial_train_targets) \n",
    "    \n",
    "    length = all_data.get_data_shape1(all_data.train_data)\n",
    "    print('processing fold build mode#', i)\n",
    "    model = build_model(length)\n",
    "    history = model.fit(partial_train_data, partial_train_targets,\n",
    "                        validation_data=(val_data, val_targets),\n",
    "                        epochs=num_epochs, batch_size=1024, verbose=1)\n",
    "    print('processing fold build mode ok#', i)\n",
    "    \n",
    "    \n",
    "    #mae_history = history.history['val_mean_absolute_error']\n",
    "    mae_history = history.history['val_mae']\n",
    "    all_mae_histories.append(mae_history)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_history = history.history['val_mae']\n",
    "all_mae_histories.append(mae_history)\n",
    "average_mae_history = [\n",
    "    np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ommit_observed_mae = 5\n",
    "def smooth_curve(points, factor=0.9):\n",
    "  smoothed_points = []\n",
    "  for point in points:\n",
    "    if smoothed_points:\n",
    "      previous = smoothed_points[-1]\n",
    "      smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "    else:\n",
    "      smoothed_points.append(point)\n",
    "  return smoothed_points\n",
    "\n",
    "smooth_mae_history = smooth_curve(average_mae_history[ommit_observed_mae:])\n",
    "\n",
    "plt.plot(range(1, len(smooth_mae_history) + 1), smooth_mae_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "# Some memory clean-up\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_observed_mae = 5\n",
    "best_epochs_num = 200\n",
    "# ommit_observed_mae + get_observed_mae\n",
    "print(best_epochs_num)\n",
    "length = all_data.get_data_shape1(all_data.train_data)\n",
    "model = build_model(length)\n",
    "model.fit(all_data.train_data, all_data.train_targets,\n",
    "                        epochs=best_epochs_num, batch_size=1024, verbose=0)\n",
    "valid_mse_socre, valid_mae_score = model.evaluate(all_data.valid_data, all_data.valid_targets, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(valid_mae_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = model.predict(all_data.test_data)\n",
    "yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('test.csv', yy, delimiter = ',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
